{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Omar\\\\Desktop\\\\Omar_Files\\\\Python_Analysis\\\\EndToEndMLProjectDemandSales\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Omar\\\\Desktop\\\\Omar_Files\\\\Python_Analysis\\\\EndToEndMLProjectDemandSales'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path:Path\n",
    "    #updated_base_model_path:Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DemandSalesRegression.constants import *\n",
    "from DemandSalesRegression.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config.prepare_base_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            #updated_base_model_path=Path(config.updated_base_model_path),\n",
    "            train_data_path= config.train_data_path,\n",
    "            test_data_path=config.test_data_path        \n",
    "            \n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from DemandSalesRegression import logger\n",
    "from DemandSalesRegression.utils.common import get_size\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self,config:PrepareBaseModelConfig):\n",
    "        self.config= config\n",
    "    \n",
    "\n",
    "    def get_data_transformer_object(self):\n",
    "        numerical_columns = ['quantity', 'price_per_case', 'total_sales']\n",
    "        categorical_columns =  ['company_region', 'product','unit']\n",
    "\n",
    "        num_pipeline= Pipeline(steps=[\n",
    "            (\"scaler\",StandardScaler())\n",
    "            ])\n",
    "        \n",
    "        cat_pipeline=Pipeline(steps=[\n",
    "            (\"OneHotEncoder\",OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "            (\"scaler\",StandardScaler(with_mean=False))\n",
    "            ])\n",
    "\n",
    "        preprocessor=ColumnTransformer([\n",
    "            (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "            (\"cat_pipelines\",cat_pipeline,categorical_columns)\n",
    "            ])  \n",
    "        \n",
    "        return preprocessor\n",
    "    \n",
    "    def initiate_data_transformation(self): \n",
    "        train_df=pd.read_csv(r\"./artifacts/data_ingestion/train_data.csv\")\n",
    "        test_df=pd.read_csv(r\"./artifacts/data_ingestion/test_data.csv\")\n",
    "\n",
    "        logger.info(\"Read train and test data completed\")\n",
    "\n",
    "        preprocessing_obj=self.get_data_transformer_object()        \n",
    "\n",
    "        target_column_name='total_sales'\n",
    "        input_column_name=['quantity', 'price_per_case', 'total_sales','company_region', 'product','unit']       \n",
    "\n",
    "        input_feature_train_df=train_df[input_column_name]\n",
    "        target_feature_train_df=train_df[target_column_name]\n",
    "\n",
    "        input_feature_test_df=test_df[input_column_name]\n",
    "        target_feature_test_df=test_df[target_column_name]     \n",
    "\n",
    "        input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "        input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "        train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "                ]\n",
    "        test_arr = np.c_[\n",
    "                 input_feature_test_arr, np.array(target_feature_test_df)\n",
    "                 ]\n",
    "        \n",
    "        if not os.path.exists(self.config.train_data_path):\n",
    "                train_arr = pd.DataFrame(train_arr)#columns=[colnames])\n",
    "                train_arr.to_csv(self.config.train_data_path,index=False)\n",
    "        if not os.path.exists(self.config.test_data_path):\n",
    "                test_arr = pd.DataFrame(test_arr)#,columns=[colnames])\n",
    "                test_arr.to_csv(self.config.test_data_path,index=False)        \n",
    "\n",
    "        return(\n",
    "                self.config.train_data_path,\n",
    "                self.config.test_data_path\n",
    "         \n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-06 21:21:11,620: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-07-06 21:21:11,622: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-06 21:21:11,624: INFO: common: created directory at: artifacts]\n",
      "[2024-07-06 21:21:11,627: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "[2024-07-06 21:21:11,667: INFO: 3280885768: Read train and test data completed]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(prepare_base_model_config)\n",
    "    prepare_base_model.get_data_transformer_object()\n",
    "    prepare_base_model.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
